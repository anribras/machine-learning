{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HMM基本算法\n",
    "\n",
    "### 概率计算\n",
    "前向，后向求观测序列概率,另外还有为模型估计的BW算法做准备的:\n",
    "\n",
    "* 前向概率$\\alpha(i)$.\n",
    "\n",
    "* 后向概率$\\beta(i)$.\n",
    "\n",
    "* 可以计算观测预测时刻t,某状态为qi的概率$\\gamma(i)$.\n",
    "\n",
    "* 可以计算观测预测时刻t,某状态为qi,时刻t+1,某状态为qj的联合概率$\\xi(i,j)$.\n",
    "\n",
    "* 根据观测预测某个状态在T内出现的期望值..\n",
    "\n",
    "### 状态序列预测\n",
    "维特比算法,动态规划算法\n",
    "\n",
    "### 学习估计模型\n",
    "Baum-Welch算法,由EM算法而来. 又叫前向后向算法，因为需要用到上面提到的前向后向概率.\n",
    "\n",
    "由EM算法可知,分为e步和q步, 不断逼近原来的极大似然估计极值(局部极值).\n",
    "\n",
    "初始值对算法的影响可能较大.\n",
    "\n",
    "**e-step** 通过$\\bar{\\lambda}$更新Q,Q是关于$\\lambda=(A,B,\\pi)$的函数 $Q(\\lambda,\\bar{\\lambda})=\\sum_{I}(O,I|\\lambda)P(O,I|\\bar{\\lambda})$\n",
    "\n",
    "**m-step** 对Q求极值，求得$\\theta^{i}$\n",
    "#### 实际问题\n",
    "由于收敛到了局部极值，如何选择初始参数将对结果有很大的影响，如何解决？\n",
    "\n",
    "## 向量化\n",
    "\n",
    "没有向量化，完全不能体现python的优势，下面看看概率计算中把前后，后向合并的一个公式:\n",
    "\n",
    "$P(O|\\lambda) = \\sum_{i=1}^{N}\\sum_{j=1}^{N}\\left( \\alpha_{t}(i)a_{ij}b_{j}(o_{t+1})\\beta_{t+1}(j) \\right) , t=1,2,3,...T-1$\n",
    "\n",
    "先不考虑i, 可以看出$\\beta$和$b$是向量点乘，而$a_{ij}$是与前面点乘是矩阵乘法的关系.\n",
    "这样i的累加通过矩阵乘法已经算完了，外围的j用向量点乘，再sum即可，即:\n",
    "```python\n",
    "    p3 = sum (np.dot(A , B[:,obs[-1]] * beta[:,-1]) * alpha[:,-2]);\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Never stop...\n",
    "* 实现似然函数，查看em算法的收敛情况.\n",
    "\n",
    "* 对比hmmlearn 看看还有哪些点没有实现.\n",
    "* Guassian HMM, GMM-HMM;\n",
    "* c++ version\n",
    "* application ! application ! application ! 语音识别"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### python实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "observe seqence probability cal(fp): (0.130218, array([[ 0.1     ,  0.077   ,  0.04187 ],\n",
      "       [ 0.16    ,  0.1104  ,  0.035512],\n",
      "       [ 0.28    ,  0.0606  ,  0.052836]]))\n",
      "observe seqence probability cal(bp): (0.130218, array([[ 0.2451,  0.54  ,  1.    ],\n",
      "       [ 0.2622,  0.49  ,  1.    ],\n",
      "       [ 0.2277,  0.57  ,  1.    ]]))\n",
      "observe seqence probability cal(total): (0.130218, array([[ 0.1     ,  0.077   ,  0.04187 ],\n",
      "       [ 0.16    ,  0.1104  ,  0.035512],\n",
      "       [ 0.28    ,  0.0606  ,  0.052836]]), array([[ 0.2451,  0.54  ,  1.    ],\n",
      "       [ 0.2622,  0.49  ,  1.    ],\n",
      "       [ 0.2277,  0.57  ,  1.    ]]), array([[ 0.18822283,  0.31931069,  0.32153773],\n",
      "       [ 0.32216744,  0.41542644,  0.27271191],\n",
      "       [ 0.48960973,  0.26526287,  0.40575036]]), array([[[ 0.1036723 ,  0.14782903,  0.        ],\n",
      "        [ 0.04515505,  0.04730529,  0.        ],\n",
      "        [ 0.03939548,  0.12417638,  0.        ]],\n",
      "\n",
      "       [[ 0.09952541,  0.12717136,  0.        ],\n",
      "        [ 0.18062019,  0.16956181,  0.        ],\n",
      "        [ 0.04202184,  0.11869327,  0.        ]],\n",
      "\n",
      "       [[ 0.11611298,  0.04653735,  0.        ],\n",
      "        [ 0.1896512 ,  0.05584481,  0.        ],\n",
      "        [ 0.18384555,  0.16288071,  0.        ]]]))\n",
      "veterbi cal: [2, 2, 2]\n",
      "iteration  1 ..\n",
      "iteration  2 ..\n",
      "iteration  3 ..\n",
      "iteration  4 ..\n",
      "iteration  5 ..\n",
      "model estimate A\n",
      " [[ 0.3377548   0.29193326  0.37031195]\n",
      " [ 0.33454365  0.27491232  0.39054403]\n",
      " [ 0.35574459  0.29066116  0.35359425]]\n",
      "model estimate B\n",
      " [[ 0.64386702  0.35613298]\n",
      " [ 0.75483979  0.24516021]\n",
      " [ 0.6025712   0.3974288 ]]\n",
      "model estimate Pi\n",
      " [ 0.30037231  0.42377453  0.27585316]\n"
     ]
    }
   ],
   "source": [
    "# %load ../HMM.py\n",
    "# HMM.py\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# delta nx1\n",
    "# A nxn\n",
    "# return nx1\n",
    "def max_delta(delta,A):\n",
    "    [m,n]=A.shape;\n",
    "    vec=np.zeros([m,1]);\n",
    "    idx=np.zeros([m,1]);\n",
    "    for i in range(n):\n",
    "        vec[i] = np.max(A[:,i] * delta);\n",
    "        idx[i] = np.argmax(A[:,i] * delta);\n",
    "    return vec.reshape(1,-1),idx.reshape(1,-1);\n",
    "\n",
    "\n",
    "# 状态空间 [1 2 3] 观测空间 [1，2](红 白)\n",
    "# 预测序列 p={红，白，红}\n",
    "# 维特比算法预测状态序列:\n",
    "def veterbi_cal(Pi,A,B,obs):\n",
    "    seq = obs;\n",
    "    times = len(seq);\n",
    "    #n为状态空间大小，m为观测空间大小\n",
    "    [n,m]=B.shape;\n",
    "    # delta初始化, 每1列代表1次观测,一共\n",
    "    # delta = [d(0),d(1),....d(times-1)]\n",
    "    # vaphi 类似\n",
    "    delta = np.zeros([n,times]);\n",
    "    vaphi = np.zeros([n,times],dtype=np.int64);\n",
    "\n",
    "    for i in range(len(seq)):\n",
    "        if(i == 0):\n",
    "            delta[:,i] = Pi * B[:,obs[i]];  \n",
    "            vaphi[:,i] = vaphi[:,i];\n",
    "        else:\n",
    "            # (1xn).T * (nx1) = nx1               \n",
    "            # 然后扩充到times列 nxtimes \n",
    "            vec,idx  = max_delta(delta[:,i-1],A);\n",
    "            delta[:,i] = vec * B[:,obs[i]]; \n",
    "            vaphi[:,i] = idx;\n",
    "    \n",
    "    state = [];\n",
    "    val = np.max(delta[:,i]);\n",
    "    # index是最后一个状态值的index\n",
    "    index = np.argmax(delta[:,i]);\n",
    "    state.insert(0,index);\n",
    "    # 反溯\n",
    "    # vaphi[:i]是类似[0;1;2]的向量，i当前反溯的最优路径的节点,vi是上一最优路径节点\n",
    "    for i in range(len(seq)-2,-1,-1):\n",
    "        index = vaphi[:,i+1][int(index)];\n",
    "        # 表头插入，表示反向\n",
    "        state.insert(0,int(index));\n",
    "    \n",
    "    return state;\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 计算观测obs的概率\n",
    "# 有前向和后向两种实现方法,还可以综合使用，得出的结果都应该是一致的\n",
    "# 输入obs = [0 1 0] (红白红)\n",
    "def forward_method(Pi,A,B,obs):\n",
    "    times = len(obs);\n",
    "    #n为状态空间大小，m为观测空间大小\n",
    "    [n,m]=B.shape;\n",
    "    #alpha 初始化 alpha(i)全部保存下来\n",
    "    alpha = np.zeros([n,times]);\n",
    "    for i in range(times):\n",
    "        if (i == 0):\n",
    "            alpha[:,i] = Pi * B[:,obs[i]];\n",
    "        else:\n",
    "            alpha[:,i] = np.dot(A.T,alpha[:,i-1]) * B[:,obs[i]];\n",
    "    #final\n",
    "    p = np.sum(alpha[:,i]);\n",
    "    return p,alpha;\n",
    "\n",
    "def backward_method(Pi,A,B,obs):\n",
    "    times = len(obs);\n",
    "    #n为状态空间大小，m为观测空间大小\n",
    "    [n,m]=B.shape;\n",
    "    #后向倒序\n",
    "    beta = np.ones([n,times]);\n",
    "    for i in range(times-1,-1,-1):\n",
    "        if(i == times -1):\n",
    "            beta[:,i] = beta[:,i]; # keep 1\n",
    "        else:\n",
    "            beta[:,i] = np.dot(A,beta[:,i+1] * B[:,obs[i+1]]);\n",
    "    #final\n",
    "    p = np.sum(Pi * B[:,obs[i]] * beta[:,i]);\n",
    "\n",
    "    return p,beta;\n",
    "\n",
    "# 可以计算观测预测时刻t,某状态为qi的概率;\n",
    "# 可以计算观测预测时刻t,某状态为qi,时刻t+1,某状态为qj的联合概率;\n",
    "# 根据观测预测某个状态在T内出现的期望值..\n",
    "def p_cal(Pi,A,B,obs):\n",
    "\n",
    "    times = len(obs);\n",
    "    [n,m] = B.shape;\n",
    "\n",
    "    [p1,alpha] = forward_method(Pi,A,B,obs);\n",
    "    [p2,beta]  = backward_method(Pi,A,B,obs);\n",
    "\n",
    "    #666\n",
    "    p3 = np.sum (np.dot(A , B[:,obs[-1]] * beta[:,-1]) * alpha[:,-2]);\n",
    "\n",
    "    # 观测预测时刻t,某状态为qi的概率; gamma\n",
    "    gamma = np.zeros([n,times]);\n",
    "    gamma = alpha * beta;  \n",
    "    s = np.sum(gamma,axis=0);\n",
    "    gamma = gamma / s[None,:];\n",
    "\n",
    "    #在已经观测下,计算预测时刻t,某状态为qi,时刻t+1,某状态为qj的联合概率;\n",
    "    # 实际上最后1次没有算，仅算到1到T-1\n",
    "    xi = np.zeros([n,n,times]);\n",
    "    parts_martix = np.zeros([n,n]);\n",
    "\n",
    "    for t in range(times-1):\n",
    "        tmp = np.dot(alpha[:,t][:,None],(beta[:,t+1]*B[:,obs[t+1]])[None,:]);\n",
    "        parts_martix =  tmp * A; \n",
    "        xi[:,:,t] =  parts_martix / np.sum(parts_martix);\n",
    "\n",
    "\n",
    "    return p3,alpha,beta,gamma,xi\n",
    "\n",
    "#输入观测序列，初始矩阵，迭代次数\n",
    "#输出估计参数\n",
    "def baum_welch_estimate(obs,init_Pi,init_A,init_B,iter_times):\n",
    "\n",
    "\n",
    "    times = len(obs);\n",
    "    [n,m] = init_B.shape;\n",
    "    #计算b的核心是构造I矩阵，\n",
    "    #k=0,t时刻的观测值必须等于vk才有效,\n",
    "    #观测序列为obs[0 1 0]\n",
    "    # k=0 时，得到 [ 1 0 1], 1 代表有效，代表无效\n",
    "    # k=1 时，得到[0 1 0]\n",
    "    #用数学来表达，构造一个矩阵\n",
    "    #       0  0 0 0 0\n",
    "    # tmp = 1  1 1 1 1  obs = [2 1 0 1] \n",
    "    #       2  2 2 2 2 \n",
    "    #tmp的每一行与obs求与即可\n",
    "    #和b的维度要一致，\n",
    "    #肯定是个nxt x txm, nxt是gamma的维度，所以构造的矩阵为txm\n",
    "    #这里直接构造好了\n",
    "    # mxt\n",
    "    I = np.ones([m,times]);\n",
    "    for i in range(m):\n",
    "        I[i,:] = I[i,:] * i;\n",
    "\n",
    "    I = np.where(I==obs,1,0) ;\n",
    "    #txm\n",
    "    I = I.T;\n",
    "    \n",
    "\n",
    "\n",
    "    A = np.zeros(init_A.shape);\n",
    "    B = np.zeros(init_B.shape);\n",
    "    Pi = np.zeros(init_Pi.shape);\n",
    "\n",
    "    for t in range(iter_times):\n",
    "        print('iteration ',t+1,'..')\n",
    "        if(t == 0):\n",
    "            p,alpha,beta,gamma,xi = p_cal(init_Pi,init_A,init_B,obs);\n",
    "        else:\n",
    "            p,alpha,beta,gamma,xi = p_cal(Pi,A,B,obs);\n",
    "        #迭代计算A,B,Pi\n",
    "\n",
    "        # 因为最后一个xi[:,:,t]为全0，\n",
    "        # 但是gamma不是,计算时要注意\n",
    "        A = np.sum(xi[:,:,:-1],axis=2) / np.sum(gamma[:,:-1],axis=1)[:,None];\n",
    "\n",
    "        \n",
    "        B = np.dot(gamma,I) / np.sum(gamma,axis=1)[:,None] ;\n",
    "\n",
    "        Pi = gamma[:,0];\n",
    "\n",
    "\n",
    "    return A,B,Pi\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    #   | 0.5 0.3 0.2 |    |0.5 0.5|\n",
    "    # A=| 0.3 0.5 0.2 | B= |0.4 0.6|\n",
    "    #   | 0.2 0.3 0.5 |    |0.7 0.3|\n",
    "    obs = [0,1,0];\n",
    "\n",
    "    A=[[0.5,0.2,0.3],[0.3,0.5,0.2],[0.2,0.3,0.5]];\n",
    "    B=[[0.5,0.5],[0.4,0.6],[0.7,0.3]];\n",
    "    Pi=[0.2,0.4,0.4];\n",
    "\n",
    "    A =np.array(A);\n",
    "    B=np.array(B);\n",
    "    Pi =np.array(Pi);\n",
    "    obs =np.array(obs);\n",
    "\n",
    "    print('observe seqence probability cal(fp):',forward_method(Pi,A,B,obs));\n",
    "    print('observe seqence probability cal(bp):',backward_method(Pi,A,B,obs));\n",
    "    print('observe seqence probability cal(total):',p_cal(Pi,A,B,obs));\n",
    "    print('veterbi cal:',veterbi_cal(Pi,A,B,obs));\n",
    "\n",
    "    # init_A = np.ones(A.shape) * 0.33333;\n",
    "    # init_B = np.ones(B.shape) * 0.5;\n",
    "    # init_Pi = np.ones(Pi.shape) * 0.3333;\n",
    "\n",
    "    A=[[0.33,0.32,0.35],[0.32,0.33,0.35],[0.35,0.31,0.34]];\n",
    "    B=[[0.49,0.51],[0.51,0.49],[0.49,0.51]];\n",
    "    Pi=[0.33,0.34,0.33];\n",
    "\n",
    "    init_A =np.array(A)\n",
    "    init_B=np.array(B)\n",
    "    init_Pi =np.array(Pi)\n",
    "\n",
    "    A,B,Pi = baum_welch_estimate(obs,init_Pi,init_A,init_B,5);\n",
    "    print('model estimate A\\n',A);\n",
    "    print('model estimate B\\n',B);\n",
    "    print('model estimate Pi\\n',Pi);\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
